{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOqKR95Q90KnNIFll8MlT1p",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tombackert/ml-stuff/blob/main/mnist_grad_cam.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# MNIST Image classification using CNN + Grad-CAM Visualization"
      ],
      "metadata": {
        "id": "vZQNXr-pkzS-"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XoM_m6Ho1LLT"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import keras\n",
        "\n",
        "from keras.datasets import mnist\n",
        "from keras.models import Model\n",
        "from keras.layers import Input, Conv2D, MaxPooling2D, Flatten, Dense\n",
        "from keras.applications import Xception  # For pre-trained model access (optional)\n",
        "from keras.preprocessing.image import load_img, img_to_array\n",
        "from keras.utils import to_categorical\n",
        "from keras import backend as K  # For accessing layer outputs\n",
        "\n",
        "# Display\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from IPython.display import Image, display\n",
        "import matplotlib as mpl\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# model\n",
        "def create_mnist_model():\n",
        "  inputs = Input(shape=(28, 28, 1))\n",
        "  x = Conv2D(32, (3, 3), activation='relu')(inputs)\n",
        "  x = MaxPooling2D((2, 2))(x)\n",
        "  x = Flatten()(x)\n",
        "  x = Dense(64, activation='relu')(x)\n",
        "  outputs = Dense(10, activation='softmax')(x)\n",
        "  model = Model(inputs=inputs, outputs=outputs)\n",
        "  return model\n"
      ],
      "metadata": {
        "id": "sN-dzhJ81kqx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load and Preprocess MNIST Data\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "\n",
        "x_train = x_train.astype('float32') / 255.0\n",
        "x_test = x_test.astype('float32') / 255.0\n",
        "y_train = to_categorical(y_train, 10)\n",
        "y_test = to_categorical(y_test, 10)\n",
        "\n",
        "# Reshape for compatibility with 2D convolutional layers\n",
        "x_train = x_train.reshape(x_train.shape[0], 28, 28, 1)\n",
        "x_test = x_test.reshape(x_test.shape[0], 28, 28, 1)\n"
      ],
      "metadata": {
        "id": "LZp5h7Nh1o6x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# train the model\n",
        "model = create_mnist_model()\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "model.fit(x_train, y_train, epochs=5, batch_size=32, validation_data=(x_test, y_test))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bsrMKLJJ128n",
        "outputId": "993e2df8-ad2d-43d7-bf7d-5a54c8a6a0ef"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "1875/1875 [==============================] - 42s 22ms/step - loss: 0.1715 - accuracy: 0.9501 - val_loss: 0.0759 - val_accuracy: 0.9771\n",
            "Epoch 2/5\n",
            "1875/1875 [==============================] - 39s 21ms/step - loss: 0.0593 - accuracy: 0.9820 - val_loss: 0.0574 - val_accuracy: 0.9821\n",
            "Epoch 3/5\n",
            "1875/1875 [==============================] - 34s 18ms/step - loss: 0.0410 - accuracy: 0.9872 - val_loss: 0.0517 - val_accuracy: 0.9848\n",
            "Epoch 4/5\n",
            "1875/1875 [==============================] - 33s 17ms/step - loss: 0.0291 - accuracy: 0.9911 - val_loss: 0.0565 - val_accuracy: 0.9829\n",
            "Epoch 5/5\n",
            "1875/1875 [==============================] - 32s 17ms/step - loss: 0.0213 - accuracy: 0.9934 - val_loss: 0.0560 - val_accuracy: 0.9835\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7e20485a3bb0>"
            ]
          },
          "metadata": {},
          "execution_count": 113
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UaqN5XfF39JV",
        "outputId": "d582dec2-454f-45da-ba3a-82f5bc37c3b2"
      },
      "execution_count": 188,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_8\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_8 (InputLayer)        [(None, 28, 28, 1)]       0         \n",
            "                                                                 \n",
            " conv2d_7 (Conv2D)           (None, 26, 26, 32)        320       \n",
            "                                                                 \n",
            " max_pooling2d_7 (MaxPoolin  (None, 13, 13, 32)        0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " flatten_7 (Flatten)         (None, 5408)              0         \n",
            "                                                                 \n",
            " dense_14 (Dense)            (None, 64)                346176    \n",
            "                                                                 \n",
            " dense_15 (Dense)            (None, 10)                650       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 347146 (1.32 MB)\n",
            "Trainable params: 347146 (1.32 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from PIL import Image\n",
        "from IPython.display import display\n",
        "\n",
        "test_image = x_test[103]\n",
        "test_image_array = test_image\n",
        "test_image = test_image.reshape(28, 28)\n",
        "test_image = (test_image * 255).astype(np.uint8)\n",
        "\n",
        "test_image = Image.fromarray(test_image, mode=\"L\")\n",
        "test_image.save('test_image.png')\n",
        "img_path = 'test_image.png'\n",
        "\n",
        "plt.matshow(test_image_array)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "VkcXQcokkhv9"
      },
      "execution_count": 187,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# parameters\n",
        "img_size = (28, 28)\n",
        "preprocess_input = keras.applications.xception.preprocess_input\n",
        "decode_predictions = keras.applications.xception.decode_predictions\n",
        "\n",
        "last_conv_layer_name = 'conv2d_7'\n",
        "\n",
        "img_path = img_path"
      ],
      "metadata": {
        "id": "1i4bQIyxEEKo"
      },
      "execution_count": 189,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 190,
      "metadata": {
        "id": "oDF__pf1pPqL"
      },
      "outputs": [],
      "source": [
        "# Grad-CAM algorithm\n",
        "\n",
        "def get_img_array(img_path, size):\n",
        "    # `img` is a PIL image of size 28x28\n",
        "    img = keras.utils.load_img(img_path, target_size=size, color_mode = \"grayscale\") # grayscale for shape (x, y, 1)\n",
        "    # `array` is a float32 Numpy array of shape (299, 299, 1)\n",
        "    array = keras.utils.img_to_array(img)\n",
        "    # We add a dimension to transform our array into a \"batch\"\n",
        "    # of size (1, 299, 299, 3)\n",
        "    array = np.expand_dims(array, axis=0)\n",
        "    return array\n",
        "\n",
        "\n",
        "def make_gradcam_heatmap(img_array, model, last_conv_layer_name, pred_index=None):\n",
        "    # First, we create a model that maps the input image to the activations\n",
        "    # of the last conv layer as well as the output predictions\n",
        "    grad_model = keras.models.Model(\n",
        "        model.inputs, [model.get_layer(last_conv_layer_name).output, model.output]\n",
        "    )\n",
        "\n",
        "    # Then, we compute the gradient of the top predicted class for our input image\n",
        "    # with respect to the activations of the last conv layer\n",
        "    with tf.GradientTape() as tape:\n",
        "        last_conv_layer_output, preds = grad_model(img_array)\n",
        "        if pred_index is None:\n",
        "            pred_index = tf.argmax(preds[0])\n",
        "        class_channel = preds[:, pred_index]\n",
        "\n",
        "    # This is the gradient of the output neuron (top predicted or chosen)\n",
        "    # with regard to the output feature map of the last conv layer\n",
        "    grads = tape.gradient(class_channel, last_conv_layer_output)\n",
        "\n",
        "    # This is a vector where each entry is the mean intensity of the gradient\n",
        "    # over a specific feature map channel\n",
        "    pooled_grads = tf.reduce_mean(grads, axis=(0, 1, 2))\n",
        "\n",
        "    # We multiply each channel in the feature map array\n",
        "    # by \"how important this channel is\" with regard to the top predicted class\n",
        "    # then sum all the channels to obtain the heatmap class activation\n",
        "    last_conv_layer_output = last_conv_layer_output[0]\n",
        "    heatmap = last_conv_layer_output @ pooled_grads[..., tf.newaxis]\n",
        "    heatmap = tf.squeeze(heatmap)\n",
        "\n",
        "    # For visualization purpose, we will also normalize the heatmap between 0 & 1\n",
        "    heatmap = tf.maximum(heatmap, 0) / tf.math.reduce_max(heatmap)\n",
        "    return heatmap.numpy()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# test-drive\n",
        "\n",
        "# Prepare image\n",
        "img_array = preprocess_input(get_img_array(img_path, size=img_size)) # we want\n",
        "\n",
        "# Make model\n",
        "model = model\n",
        "\n",
        "# Remove last layer's softmax\n",
        "model.layers[-1].activation = None\n",
        "\n",
        "# Print what the top predicted class is\n",
        "preds = model.predict(img_array)\n",
        "print(\"Predicted:\", preds)\n",
        "\n",
        "# Generate class activation heatmap\n",
        "heatmap = make_gradcam_heatmap(img_array, model, last_conv_layer_name)\n",
        "\n",
        "# Display heatmap\n",
        "plt.matshow(heatmap)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZlY6YLRhLIO8",
        "outputId": "f6ab45dc-40d1-4087-d61c-a0d9d75fe853"
      },
      "execution_count": 191,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 22ms/step\n",
            "Predicted: [[-113.84946     67.110275    -8.480155   -78.22684     69.039566\n",
            "     3.0158675  -86.43222     20.753073  -106.41469    -38.91964  ]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "heatmap.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gv-WI-zyeqop",
        "outputId": "2d632b24-7fde-47ec-afb9-e2b3307646d2"
      },
      "execution_count": 192,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(26, 26)"
            ]
          },
          "metadata": {},
          "execution_count": 192
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# create visualization\n",
        "import matplotlib.colors as colors\n",
        "\n",
        "def save_and_display_gradcam(img_path, heatmap, cam_path=\"cam.jpg\", alpha=0.4):\n",
        "    # Load the original image\n",
        "    img = keras.utils.load_img(img_path)\n",
        "    img = keras.utils.img_to_array(img)\n",
        "\n",
        "    # Rescale heatmap to a range 0-255\n",
        "    heatmap = np.uint8(255 * heatmap)\n",
        "\n",
        "    # Use jet colormap to colorize heatmap\n",
        "    colormap = mpl.colormaps[\"gnuplot2\"]\n",
        "\n",
        "    # Use RGB values of the colormap\n",
        "    colormap_colors = colormap(np.arange(256))[:, :3]\n",
        "    colormap_heatmap = colormap_colors[heatmap]\n",
        "\n",
        "    plt.figure()\n",
        "    plt.matshow(colormap_heatmap)\n",
        "    plt.colorbar(mpl.cm.ScalarMappable(cmap=colormap), label=\"Relevance\", boundaries=np.linspace(0, 1, 6), ax=plt.gca())\n",
        "    plt.show()\n",
        "\n",
        "save_and_display_gradcam(img_path, heatmap)"
      ],
      "metadata": {
        "id": "0BR4au3FLNCg"
      },
      "execution_count": 193,
      "outputs": []
    }
  ]
}